#!/usr/bin/env python3.6

import argparse
import glob
import os
import datetime
import dateparser
from elasticsearch import Elasticsearch
from elasticsearch.helpers import scan


maxEntries = 50000

filePrefix = """<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
"""

entryTemplate = """<url>
 <loc>{url}</loc>
 <lastmod>{lastmod}</lastmod>
 <changefreq>weekly</changefreq>
</url>"""

fileSuffix = """
</urlset>
"""

robotsTxt = """User-Agent: *
Disallow:

"""


def addEntry(handle, doc, outputDir):
    lastmod = dateparser.parse(doc.get('time', doc.get('import_date', datetime.datetime.now()))).date().isoformat()
    url = f'http://naematel.com/{doc["_id"]}'
    entry = entryTemplate.format(url=url, lastmod=lastmod)
    if not handle[0]:
        newFilename = f'sitemap-{handle[1]}.xml'
        print('Writing in:', newFilename)
        handle[0] = open(os.path.join(outputDir, newFilename), 'w')
        handle[1] += 1
        handle.append(newFilename)
        handle[0].write(filePrefix)

    handle[0].write(entry)
    return handle


def genSitemap(outputDir, index):
    count = 0
    handle = [None, 1]
    for doc in scan(es, index=index, doc_type='ad'):
        doc['_source']['_id'] = doc['_id']
        addEntry(handle, doc['_source'], outputDir)
        count += 1
        if count >= maxEntries:
            handle[0].write(fileSuffix)
            handle[0].close()
            handle[0] = None
            count = 0

    if handle[0]:
        handle[0].write(fileSuffix)
        handle[0].close()

    robots = f'robots.txt'
    print('Writing in:', robots)
    with open(os.path.join(outputDir, robots), 'w') as f:
        f.write(robotsTxt)
        for sm in handle[2:]:
            f.write(f'Sitemap: {sm}\n')


def removeSitemaps(outDir):
    for fmt in ['xml', 'txt']:
        for f in glob.glob(os.path.join(outDir, 'sitemap-*.' + fmt)):
            print('Remove:', f)
            os.unlink(f)


usage = "usage: %prog <feed>"
description = "Generate sitemap files"
parser = argparse.ArgumentParser(description=description)
parser.add_argument("out",
                    help="output directory")
parser.add_argument("-i", "--index",
                    default='rentbot-all',
                    help="Index name")
args = parser.parse_args()

es = Elasticsearch(['localhost:9200'])

os.makedirs(args.out, exist_ok=True)
removeSitemaps(args.out)

genSitemap(args.out, args.index)

##
