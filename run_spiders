#!/usr/bin/env python

import os
import datetime
import subprocess

SPIDERS = {
    'olx': None,
    'imot': None,
    'fbGroup': [
        'https://m.facebook.com/groups/kvartiti.pod.naem/',
        'https://m.facebook.com/groups/apartamenti.sofia/',
    ]
}
STOP_AFTER_SKIPPED = 10

DATA_DIR = '/srv/'
DATA_DIR = './_test/'


RUN_DIR = DATA_DIR + 'crawl/' + datetime.datetime.now().strftime("%Y-%m-%dT%H:%M")
FEEDS_DIR = DATA_DIR + 'feeds/'

os.makedirs(RUN_DIR, exist_ok=True)
os.makedirs(FEEDS_DIR, exist_ok=True)


def runSpider(spiderName, url, full=False):
    feedFile = f'{spiderName}.jl'
    feedPath = os.path.join(RUN_DIR, feedFile)
    logPath = os.path.join(RUN_DIR, f'{spiderName}.log')
    command = [
        'echo', f'{spiderName}',
        '--set', f'FEED_URI=file://{feedPath}',
        '--set', 'DELTAFETCH_ENABLED=1',
    ]
    if not full:
        command += [
            '--set', 'STOP_AFTER_SKIPPED={STOP_AFTER_SKIPPED}',
        ]
    if full:
        command += [
            '--set', 'DELTAFETCH_RESET=1'
        ]
    if url:
        command += [f' --set START_URL={url}']
    with open(logPath, 'a+') as log:
        subprocess.run(command, stdout=log, stderr=log)
    return feedPath


def copyFeeds(spiderName, feedPath):
    try:
        feedSize = os.path.getsize(feedPath)
    except:
        feedSize = 0
    if feedSize > 0:
        os.rename(feedPath, os.path.join(FEEDS_DIR, f'{spiderName}.jl'))

for spiderName, urls in SPIDERS.items():
    if urls:
        for url in urls:
            runSpider(spiderName, url)
    else:
        runSpider(spiderName, None)
